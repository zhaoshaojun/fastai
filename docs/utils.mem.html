---

title: utils.mem
keywords: 
sidebar: home_sidebar


---

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="utils.mem">utils.mem<a class="anchor-link" href="#utils.mem">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Utility functions for memory management (mainly GPU).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GPUMemTrace"><code>class</code> <code>GPUMemTrace</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L153" class="source_link">[source]</a></h2><blockquote><p><code>GPUMemTrace</code>(<strong><code>silent</code></strong>=<strong><em><code>False</code></em></strong>)</p>
</blockquote>
<p>Trace GPU allocated and peak memory usage</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Usage examples:</p>

<pre><code>memtrace = GPUMemTrace()
memtrace.start() start tracing

some_code()
memtrace.report() print intermediary cumulative report
used, peak =  memtrace.data() same but as data

some_code()
memtrace.report('2nd run') print intermediary cumulative report
used, peak =  memtrace.data()

for i in range(10):
    memtrace.reset()
    code()
    memtrace.report(f'i={i}') report for just the last code run since reset

# combine report+reset
memtrace.reset()
for i in range(10):
    code()
    memtrace.report_n_reset(f'i={i}') report for just the last code run since reset

memtrace.stop() # stop the monitor thread</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GPUMemory"><code>class</code> <code>GPUMemory</code></h2><blockquote><p><code>GPUMemory</code>(<strong><code>total</code></strong>, <strong><code>used</code></strong>, <strong><code>free</code></strong>) :: <code>tuple</code></p>
</blockquote>
<p>GPUMemory(total, used, free)</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>GPUMemory</code> is a namedtuple that is returned by functions like <code>gpu_mem_get</code> and <code>gpu_mem_get_all</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="b2mb"><code>b2mb</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L22" class="source_link">[source]</a></h4><blockquote><p><code>b2mb</code>(<strong><code>num</code></strong>)</p>
</blockquote>
<p>convert Bs to MBs and round down</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>b2mb</code> is a helper utility that just does <code>int(bytes/2**20)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get"><code>gpu_mem_get</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L29" class="source_link">[source]</a></h4><blockquote><p><code>gpu_mem_get</code>(<strong><code>id</code></strong>=<strong><em><code>None</code></em></strong>)</p>
</blockquote>
<p>get total, used and free memory (in MBs) for gpu <code>id</code>. if <code>id</code> is not passed, currently selected torch device is used</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>gpu_mem_get</code></p>
<ul>
<li>for gpu returns <code>GPUMemory(total, used, free)</code></li>
<li>for cpu returns <code>GPUMemory(0, 0, 0)</code></li>
<li>for invalid gpu id returns <code>GPUMemory(0, 0, 0)</code></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get_all"><code>gpu_mem_get_all</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L42" class="source_link">[source]</a></h4><blockquote><p><code>gpu_mem_get_all</code>()</p>
</blockquote>
<p>get total, used and free memory (in MBs) for each available gpu</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>gpu_mem_get_all</code></p>
<ul>
<li>for gpu returns <code>[ GPUMemory(total_0, used_0, free_0), GPUMemory(total_1, used_1, free_1), .... ]</code></li>
<li>for cpu returns <code>[]</code></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get_free_no_cache"><code>gpu_mem_get_free_no_cache</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L47" class="source_link">[source]</a></h4><blockquote><p><code>gpu_mem_get_free_no_cache</code>()</p>
</blockquote>
<p>get free memory (in MBs) for the currently selected gpu id, after emptying the cache</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>gpu_mem_get_free_no_cache</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get_used_no_cache"><code>gpu_mem_get_used_no_cache</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L52" class="source_link">[source]</a></h4><blockquote><p><code>gpu_mem_get_used_no_cache</code>()</p>
</blockquote>
<p>get used memory (in MBs) for the currently selected gpu id, after emptying the cache</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>gpu_mem_get_used_no_cache</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get_fast_used"><code>gpu_mem_get_fast_used</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L57" class="source_link">[source]</a></h4><blockquote><p><code>gpu_mem_get_fast_used</code>(<strong><code>gpu_handle</code></strong>)</p>
</blockquote>
<p>get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache, and needing the <code>gpu_handle</code> arg</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>gpu_mem_get_fast_used</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_with_max_free_mem"><code>gpu_with_max_free_mem</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L64" class="source_link">[source]</a></h4><blockquote><p><code>gpu_with_max_free_mem</code>()</p>
</blockquote>
<p>get [gpu_id, its_free_ram] for the first gpu with highest available RAM</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>gpu_with_max_free_mem</code>:</p>
<ul>
<li>for gpu returns: <code>gpu_with_max_free_ram_id, its_free_ram</code></li>
<li>for cpu returns: <code>None, 0</code></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="preload_pytorch"><code>preload_pytorch</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L19" class="source_link">[source]</a></h4><blockquote><p><code>preload_pytorch</code>()</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>preload_pytorch</code> is helpful when GPU memory is being measured, since the first time any operation on <code>cuda</code> is performed by pytorch, usually about 0.5GB gets used by CUDA context.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Workarounds-to-the-leaky-ipython-traceback">Workarounds to the leaky ipython traceback<a class="anchor-link" href="#Workarounds-to-the-leaky-ipython-traceback">&#182;</a></h2><p>ipython has a feature where it stores tb with all the <code>locals()</code> tied in, which
prevents <code>gc.collect()</code> from freeing those variables and leading to a leakage.</p>
<p>Therefore we cleanse the tb before handing it over to ipython. The 2 ways of doing it are by either using the <code>gpu_mem_restore</code> decorator or the <code>gpu_mem_restore_ctx</code> context manager which are described next:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_restore"><code>gpu_mem_restore</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L94" class="source_link">[source]</a></h4><blockquote><p><code>gpu_mem_restore</code>(<strong><code>func</code></strong>)</p>
</blockquote>
<p>Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>gpu_mem_restore</code> is a decorator to be used with any functions that interact with CUDA (top-level is fine)</p>
<ul>
<li>under non-ipython environment it doesn't do anything.</li>
<li>under ipython currently it strips tb by default only for the "CUDA out of memory" exception.</li>
</ul>
<p>The env var <code>FASTAI_TB_CLEAR_FRAMES</code> changes this behavior when run under ipython,
depending on its value:</p>
<ul>
<li>"0": never  strip tb (makes it possible to always use <code>%debug</code> magic, but with leaks)</li>
<li>"1": always strip tb (never need to worry about leaks, but <code>%debug</code> won't work)</li>
</ul>
<p>e.g. <code>os.environ['FASTAI_TB_CLEAR_FRAMES']="0"</code> will set it to 0.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="gpu_mem_restore_ctx"><code>class</code> <code>gpu_mem_restore_ctx</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L118" class="source_link">[source]</a></h2><blockquote><p><code>gpu_mem_restore_ctx</code>()</p>
</blockquote>
<p>context manager to reclaim RAM if an exception happened under ipython</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>if function decorator is not a good option, you can use a context manager instead. For example:</p>

<pre><code>with gpu_mem_restore_ctx():
   learn.fit_one_cycle(1,1e-2)</code></pre>
<p>This particular one will clear tb on any exception.</p>

</div>
</div>
</div>
</div>
 

