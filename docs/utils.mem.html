---

title: utils.mem
keywords: 
sidebar: home_sidebar


---

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Memory-management-utils">Memory management utils<a class="anchor-link" href="#Memory-management-utils">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Utility functions for memory management. Currently primarily for GPU.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get"><code>gpu_mem_get</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L27" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_mem_get-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_mem_get</code>(<strong><code>id</code></strong>=<strong><em><code>None</code></em></strong>)</p>
</blockquote>
<p>get total, used and free memory (in MBs) for gpu <code>id</code>. if <code>id</code> is not passed, currently selected torch device is used</p>
<div class="collapse" id="gpu_mem_get-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_mem_get-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>Tests found for <code>gpu_mem_get</code>:</p><p>This tests:</p><ul><li><code>pytest -sv tests/test_utils_mem.py::test_gpu_mem_by_id</code> <a href="https://github.com/fastai/fastai/blob/master/tests/test_utils_mem.py#L25" class="source_link" style="float:right">[source]</a></li></ul></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/utils.mem.html#gpu_mem_get"><code>gpu_mem_get</code></a></p>
<ul>
<li>for gpu returns <code>GPUMemory(total, free, used)</code></li>
<li>for cpu returns <code>GPUMemory(0, 0, 0)</code></li>
<li>for invalid gpu id returns <code>GPUMemory(0, 0, 0)</code></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get_all"><code>gpu_mem_get_all</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L38" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_mem_get_all-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_mem_get_all</code>()</p>
</blockquote>
<p>get total, used and free memory (in MBs) for each available gpu</p>
<div class="collapse" id="gpu_mem_get_all-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_mem_get_all-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>Tests found for <code>gpu_mem_get_all</code>:</p><p>This tests:</p><ul><li><code>pytest -sv tests/test_utils_mem.py::test_gpu_mem_all</code> <a href="https://github.com/fastai/fastai/blob/master/tests/test_utils_mem.py#L35" class="source_link" style="float:right">[source]</a></li></ul></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/utils.mem.html#gpu_mem_get_all"><code>gpu_mem_get_all</code></a></p>
<ul>
<li>for gpu returns <code>[ GPUMemory(total_0, free_0, used_0), GPUMemory(total_1, free_1, used_1), .... ]</code></li>
<li>for cpu returns <code>[]</code></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get_free"><code>gpu_mem_get_free</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L43" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_mem_get_free-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_mem_get_free</code>()</p>
</blockquote>
<p>get free memory (in MBs) for the currently selected gpu id, w/o emptying the cache</p>
<div class="collapse" id="gpu_mem_get_free-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_mem_get_free-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>gpu_mem_get_free</code></p></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get_free_no_cache"><code>gpu_mem_get_free_no_cache</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L47" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_mem_get_free_no_cache-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_mem_get_free_no_cache</code>()</p>
</blockquote>
<p>get free memory (in MBs) for the currently selected gpu id, after emptying the cache</p>
<div class="collapse" id="gpu_mem_get_free_no_cache-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_mem_get_free_no_cache-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>gpu_mem_get_free_no_cache</code></p></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get_used"><code>gpu_mem_get_used</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L52" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_mem_get_used-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_mem_get_used</code>()</p>
</blockquote>
<p>get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache</p>
<div class="collapse" id="gpu_mem_get_used-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_mem_get_used-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>Tests found for <code>gpu_mem_get_used</code>:</p><p>This tests:</p><ul><li><code>pytest -sv tests/test_utils_mem.py::test_gpu_mem_measure_consumed_reclaimed</code> <a href="https://github.com/fastai/fastai/blob/master/tests/test_utils_mem.py#L56" class="source_link" style="float:right">[source]</a></li></ul></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get_used_no_cache"><code>gpu_mem_get_used_no_cache</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L61" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_mem_get_used_no_cache-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_mem_get_used_no_cache</code>()</p>
</blockquote>
<p>get used memory (in MBs) for the currently selected gpu id, after emptying the cache</p>
<div class="collapse" id="gpu_mem_get_used_no_cache-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_mem_get_used_no_cache-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>gpu_mem_get_used_no_cache</code></p></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/utils.mem.html#gpu_mem_get_used_no_cache"><code>gpu_mem_get_used_no_cache</code></a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_get_used_fast"><code>gpu_mem_get_used_fast</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L56" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_mem_get_used_fast-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_mem_get_used_fast</code>(<strong><code>gpu_handle</code></strong>)</p>
</blockquote>
<p>get used memory (in MBs) for the currently selected gpu id, w/o emptying the cache, and needing the <code>gpu_handle</code> arg</p>
<div class="collapse" id="gpu_mem_get_used_fast-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_mem_get_used_fast-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>gpu_mem_get_used_fast</code></p></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/utils.mem.html#gpu_mem_get_used_fast"><code>gpu_mem_get_used_fast</code></a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_with_max_free_mem"><code>gpu_with_max_free_mem</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L66" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_with_max_free_mem-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_with_max_free_mem</code>()</p>
</blockquote>
<p>get [gpu_id, its_free_ram] for the first gpu with highest available RAM</p>
<div class="collapse" id="gpu_with_max_free_mem-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_with_max_free_mem-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>Tests found for <code>gpu_with_max_free_mem</code>:</p><p>This tests:</p><ul><li><code>pytest -sv tests/test_utils_mem.py::test_gpu_with_max_free_mem</code> <a href="https://github.com/fastai/fastai/blob/master/tests/test_utils_mem.py#L44" class="source_link" style="float:right">[source]</a></li></ul></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/utils.mem.html#gpu_with_max_free_mem"><code>gpu_with_max_free_mem</code></a>:</p>
<ul>
<li>for gpu returns: <code>gpu_with_max_free_ram_id, its_free_ram</code></li>
<li>for cpu returns: <code>None, 0</code></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="preload_pytorch"><code>preload_pytorch</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L20" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#preload_pytorch-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>preload_pytorch</code>()</p>
</blockquote>
<div class="collapse" id="preload_pytorch-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#preload_pytorch-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>preload_pytorch</code></p></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/utils.mem.html#preload_pytorch"><code>preload_pytorch</code></a> is helpful when GPU memory is being measured, since the first time any operation on <code>cuda</code> is performed by pytorch, usually about 0.5GB gets used by CUDA context.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="GPUMemory"><code>class</code> <code>GPUMemory</code><a class="source_link" data-toggle="collapse" data-target="#GPUMemory-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>GPUMemory</code>(<strong><code>total</code></strong>, <strong><code>free</code></strong>, <strong><code>used</code></strong>) :: <code>tuple</code></p>
</blockquote>
<p>GPUMemory(total, free, used)</p>
<div class="collapse" id="GPUMemory-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#GPUMemory-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>GPUMemory</code></p></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/utils.mem.html#GPUMemory"><code>GPUMemory</code></a> is a namedtuple that is returned by functions like <a href="/utils.mem.html#gpu_mem_get"><code>gpu_mem_get</code></a> and <a href="/utils.mem.html#gpu_mem_get_all"><code>gpu_mem_get_all</code></a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="b2mb"><code>b2mb</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L23" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#b2mb-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>b2mb</code>(<strong><code>num</code></strong>)</p>
</blockquote>
<p>convert Bs to MBs and round down</p>
<div class="collapse" id="b2mb-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#b2mb-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>b2mb</code></p></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/utils.mem.html#b2mb"><code>b2mb</code></a> is a helper utility that just does <code>int(bytes/2**20)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Memory-Tracing-Utils">Memory Tracing Utils<a class="anchor-link" href="#Memory-Tracing-Utils">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="GPUMemTrace"><code>class</code> <code>GPUMemTrace</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L111" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#GPUMemTrace-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>GPUMemTrace</code>(<strong><code>silent</code></strong>=<strong><em><code>False</code></em></strong>, <strong><code>ctx</code></strong>=<strong><em><code>None</code></em></strong>, <strong><code>on_exit_report</code></strong>=<strong><em><code>True</code></em></strong>)</p>
</blockquote>
<p>Trace allocated and peaked GPU memory usage (deltas).</p>
<div class="collapse" id="GPUMemTrace-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#GPUMemTrace-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>Tests found for <code>GPUMemTrace</code>:</p><p>This tests:</p><ul><li><code>pytest -sv tests/test_utils_mem.py::test_gpu_mem_trace</code> <a href="https://github.com/fastai/fastai/blob/master/tests/test_utils_mem.py#L76" class="source_link" style="float:right">[source]</a></li><li><code>pytest -sv tests/test_utils_mem.py::test_gpu_mem_trace_ctx</code> <a href="https://github.com/fastai/fastai/blob/master/tests/test_utils_mem.py#L137" class="source_link" style="float:right">[source]</a></li></ul></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Arguments</strong>:</p>
<ul>
<li><code>silent</code>: a shortcut to make <code>report</code> and <code>report_n_reset</code> silent w/o needing to remove those calls - this can be done from the constructor, or alternatively you can call <code>silent</code> method anywhere to do the same.</li>
<li><code>ctx</code>: default context note in reports</li>
<li><code>on_exit_report</code>:  auto-report on ctx manager exit (default <code>True</code>)</li>
</ul>
<p><strong>Definitions</strong>:</p>
<ul>
<li><p><strong>Delta Used</strong> is the difference between current used memory and used memory at the start of the counter.</p>
</li>
<li><p><strong>Delta Peaked</strong> is the memory overhead if any. It's calculated in two steps:</p>
<ol>
<li>The base measurement is the difference between the peak memory and the used memory at the start of the counter.</li>
<li><p>Then if delta used is positive it gets subtracted from the base value.</p>
<p>It indicates the size of the blip.</p>
<p><strong>Warning</strong>: currently the peak memory usage tracking is implemented using a python thread, which is very unreliable, since there is no guarantee the thread will get a chance at running at the moment the peak memory is occuring (or it might not get a chance to run at all). Therefore we need pytorch to implement multiple concurrent and resettable <a href="https://pytorch.org/docs/stable/cuda.html#torch.cuda.max_memory_allocated"><code>torch.cuda.max_memory_allocated</code></a> counters. Please vote for this <a href="https://github.com/pytorch/pytorch/issues/16266">feature request</a>.</p>
</li>
</ol>
</li>
</ul>
<p><strong>Usage Examples</strong>:</p>
<p>Setup:</p>

<pre><code>from fastai.utils.mem import GPUMemTrace
def some_code(): pass
mtrace = GPUMemTrace()</code></pre>
<p>Example 1: basic measurements via <code>report</code> (prints) and via <a href="/tabular.data.html#tabular.data"><code>data</code></a> (returns) accessors</p>

<pre><code>some_code()
mtrace.report()
delta_used, delta_peaked = mtrace.data()

some_code()
mtrace.report('2nd run of some_code()')
delta_used, delta_peaked = mtrace.data()</code></pre>
<p><code>report</code>'s optional <code>subctx</code> argument can be helpful if you have many <code>report</code> calls and you want to understand which is which in the outputs.</p>
<p>Example 2: measure in a loop, resetting the counter before each run</p>

<pre><code>for i in range(10):
    mtrace.reset()
    some_code()
    mtrace.report(f'i={i}')</code></pre>
<p><code>reset</code> resets all the counters.</p>
<p>Example 3: like example 2, but having <code>report</code> automatically reset the counters</p>

<pre><code>mtrace.reset()
for i in range(10):
    some_code()
    mtrace.report_n_reset(f'i={i}')</code></pre>
<p>The tracing starts immediately upon the <a href="/utils.mem.html#GPUMemTrace"><code>GPUMemTrace</code></a> object creation, and stops when that object is deleted. But it can also be <code>stop</code>ed, <code>start</code>ed manually as well.</p>

<pre><code>mtrace.start()
mtrace.stop()</code></pre>
<p><code>stop</code> is in particular useful if you want to <strong>freeze</strong> the <a href="/utils.mem.html#GPUMemTrace"><code>GPUMemTrace</code></a> object and to be able to query its data on <code>stop</code> some time down the road.</p>
<p><strong>Reporting</strong>:</p>
<p>In reports you can print a main context passed via the constructor:</p>

<pre><code>mtrace = GPUMemTrace(ctx="foobar")
mtrace.report()</code></pre>
<p>prints:</p>

<pre><code>△Used Peaked MB:      0      0  (foobar)</code></pre>
<p>and then add subcontext notes as needed:</p>

<pre><code>mtrace = GPUMemTrace(ctx="foobar")
mtrace.report('1st try')
mtrace.report('2nd try')</code></pre>
<p>prints:</p>

<pre><code>△Used Peaked MB:      0      0  (foobar: 1st try)
△Used Peaked MB:      0      0  (foobar: 2nd try)</code></pre>
<p>Both context and sub-context are optional, and are very useful if you sprinkle <a href="/utils.mem.html#GPUMemTrace"><code>GPUMemTrace</code></a> in different places around the code.</p>
<p>You can silence report calls w/o needing to remove them via constructor or <code>silent</code>:</p>

<pre><code>mtrace = GPUMemTrace(silent=True)
mtrace.report() # nothing will be printed
mtrace.silent(silent=False)
mtrace.report() # printing resumed
mtrace.silent(silent=True)
mtrace.report() # nothing will be printed</code></pre>
<p><strong>Context Manager</strong>:</p>
<p><a href="/utils.mem.html#GPUMemTrace"><code>GPUMemTrace</code></a> can also be used as a context manager:</p>
<p>Report the used and peaked deltas automatically:</p>

<pre><code>with GPUMemTrace(): some_code()</code></pre>
<p>If you wish to add context:</p>

<pre><code>with GPUMemTrace(ctx='some context'): some_code()</code></pre>
<p>The context manager uses subcontext <code>exit</code> to indicate that the report comes after the context exited.</p>
<p>The reporting is done automatically, which is especially useful in functions due to return call:</p>

<pre><code>def some_func():
    with GPUMemTrace(ctx='some_func'):
        # some code
        return 1
some_func()</code></pre>
<p>prints:</p>

<pre><code>△Used Peaked MB:      0      0 (some_func: exit)</code></pre>
<p>so you still get a perfect report despite the <code>return</code> call here. <code>ctx</code> is useful for specifying the <em>context</em> in case you have many of those calls through your code and you want to know which is which.</p>
<p>And, of course, instead of doing the above, you can use <a href="/utils.mem.html#gpu_mem_trace"><code>gpu_mem_trace</code></a> decorator to do it automatically, including using the function or method name as the context. Therefore, the example below does the same without modifying the function.</p>

<pre><code>@gpu_mem_trace
def some_func():
    # some code
    return 1
some_func()</code></pre>
<p>If you don't wish the automatic reporting, just pass <code>on_exit_report=False</code> in the constructor:</p>

<pre><code>with GPUMemTrace(ctx='some_func', on_exit_report=False) as mtrace:
    some_code()
mtrace.report("measured in ctx")</code></pre>
<p>or the same w/o the context note:</p>

<pre><code>with GPUMemTrace(on_exit_report=False) as mtrace: some_code()
print(mtrace) # or mtrace.report()</code></pre>
<p>And, of course, you can get the numerical data (in rounded MBs):</p>

<pre><code>with GPUMemTrace() as mtrace: some_code()
delta_used, delta_peaked = mtrace.data()</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_trace"><code>gpu_mem_trace</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L208" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_mem_trace-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_mem_trace</code>(<strong><code>func</code></strong>)</p>
</blockquote>
<p>A decorator that runs <a href="/utils.mem.html#GPUMemTrace"><code>GPUMemTrace</code></a> w/ report on func</p>
<div class="collapse" id="gpu_mem_trace-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_mem_trace-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>Tests found for <code>gpu_mem_trace</code>:</p><p>This tests:</p><ul><li><code>pytest -sv tests/test_utils_mem.py::test_gpu_mem_trace_decorator</code> <a href="https://github.com/fastai/fastai/blob/master/tests/test_utils_mem.py#L178" class="source_link" style="float:right">[source]</a></li></ul></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This allows you to decorate any function or method with:</p>

<pre><code>@gpu_mem_trace
def my_function(): pass
# run:
my_function()</code></pre>
<p>and it will automatically print the report including the function name as a context:</p>

<pre><code>△Used Peaked MB:      0      0 (my_function: exit)</code></pre>
<p>In the case of methods it'll print a fully qualified method, e.g.:</p>

<pre><code>△Used Peaked MB:      0      0 (Class.function: exit)</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Workarounds-to-the-leaky-ipython-traceback-on-exception">Workarounds to the leaky ipython traceback on exception<a class="anchor-link" href="#Workarounds-to-the-leaky-ipython-traceback-on-exception">&#182;</a></h2><p>ipython has a feature where it stores tb with all the <code>locals()</code> tied in, which
prevents <code>gc.collect()</code> from freeing those variables and leading to a leakage.</p>
<p>Therefore we cleanse the tb before handing it over to ipython. The 2 ways of doing it are by either using the <a href="/utils.mem.html#gpu_mem_restore"><code>gpu_mem_restore</code></a> decorator or the <a href="/utils.mem.html#gpu_mem_restore_ctx"><code>gpu_mem_restore_ctx</code></a> context manager which are described next:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_restore"><code>gpu_mem_restore</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L80" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_mem_restore-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_mem_restore</code>(<strong><code>func</code></strong>)</p>
</blockquote>
<p>Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted</p>
<div class="collapse" id="gpu_mem_restore-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_mem_restore-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>gpu_mem_restore</code></p></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="/utils.mem.html#gpu_mem_restore"><code>gpu_mem_restore</code></a> is a decorator to be used with any functions that interact with CUDA (top-level is fine)</p>
<ul>
<li>under non-ipython environment it doesn't do anything.</li>
<li>under ipython currently it strips tb by default only for the "CUDA out of memory" exception.</li>
</ul>
<p>The env var <code>FASTAI_TB_CLEAR_FRAMES</code> changes this behavior when run under ipython,
depending on its value:</p>
<ul>
<li>"0": never  strip tb (makes it possible to always use <code>%debug</code> magic, but with leaks)</li>
<li>"1": always strip tb (never need to worry about leaks, but <code>%debug</code> won't work)</li>
</ul>
<p>e.g. <code>os.environ['FASTAI_TB_CLEAR_FRAMES']="0"</code> will set it to 0.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gpu_mem_restore_ctx"><code>class</code> <code>gpu_mem_restore_ctx</code><a href="https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py#L102" class="source_link" style="float:right">[source]</a><a class="source_link" data-toggle="collapse" data-target="#gpu_mem_restore_ctx-pytest" style="float:right; padding-right:10px">[test]</a></h4><blockquote><p><code>gpu_mem_restore_ctx</code>()</p>
</blockquote>
<p>context manager to reclaim RAM if an exception happened under ipython</p>
<div class="collapse" id="gpu_mem_restore_ctx-pytest"><div class="card card-body pytest_card"><a type="button" data-toggle="collapse" data-target="#gpu_mem_restore_ctx-pytest" class="close" aria-label="Close"><span aria-hidden="true">&times;</span></a><p>No tests found for <code>gpu_mem_restore_ctx</code></p></div></div><div style="height:1px"></div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>if function decorator is not a good option, you can use a context manager instead. For example:</p>

<pre><code>with gpu_mem_restore_ctx():
   learn.fit_one_cycle(1,1e-2)</code></pre>
<p>This particular one will clear tb on any exception.</p>

</div>
</div>
</div>
</div>
 

