{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.nlp import *\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH='data/aclImdb/'\n",
    "names = ['neg','pos']\n",
    "names1 = ['neg', 'pos_']\n",
    "names2 = ['neg_', 'pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeledBow.feat \u001b[34mpos\u001b[m\u001b[m             unsupBow.feat   urls_pos.txt\r\n",
      "\u001b[34mneg\u001b[m\u001b[m             \u001b[34munsup\u001b[m\u001b[m           urls_neg.txt    urls_unsup.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls {PATH}train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn1,trn1_y = texts_labels_from_folders(f'{PATH}train',names1)\n",
    "val1,val1_y = texts_labels_from_folders(f'{PATH}test',names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn2,trn2_y = texts_labels_from_folders(f'{PATH}train',names2)\n",
    "val2,val2_y = texts_labels_from_folders(f'{PATH}test',names2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn1), len(trn1_y), len(trn2), len(trn2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert (trn1_y==0).all()\n",
    "(trn1_y==0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert (trn1_y==0).all()\n",
    "(val1_y==0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert (trn2_y==1).all()\n",
    "(trn2_y==1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert (val2_y==1).all()\n",
    "(val2_y==1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sample_util(data, label, n):\n",
    "    assert len(data) == label.shape[0]\n",
    "    idx = np.random.choice(range(len(data)),n)\n",
    "    data_new = [data[i] for i in idx]\n",
    "    label_new = label[idx]\n",
    "    return data_new, label_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sample(data1, label1, data2, label2, n):\n",
    "    t1, t2 = sample_util(data1, label1, n)\n",
    "    t3, t4 = sample_util(data2, label2, n)\n",
    "    data = t1 + t3\n",
    "    label = np.concatenate((t2, t4))\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn, trn_y = sample(trn1, trn1_y, trn2, trn2_y, 64*10)\n",
    "val, val_y = sample(val1, val1_y, val2, val2_y, 64*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# trn,trn_y = texts_labels_from_folders(f'{PATH}train',names)\n",
    "# val,val_y = texts_labels_from_folders(f'{PATH}test',names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## create vectors and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "veczr = CountVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_term_doc = veczr.fit_transform(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_term_doc = veczr.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dictatorship', 'diction', 'dictionary', 'did', 'diddle']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = veczr.get_feature_names(); vocab[5000:5005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '\"', '#', '$', '%']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20001"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_term_doc = trn_term_doc.sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_term_doc = val_term_doc.sign()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the **log-count ratio** $r$ for each word $f$:\n",
    "\n",
    "$r = \\log \\frac{\\text{ratio of feature $f$ in positive documents}}{\\text{ratio of feature $f$ in negative documents}}$\n",
    "\n",
    "where ratio of feature $f$ in positive documents is the number of times a positive document has a feature divided by the number of positive documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(y_i):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return p+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=trn_term_doc\n",
    "y=trn_y\n",
    "\n",
    "p = pr(1)/pr(1).sum()\n",
    "q = pr(0)/pr(0).sum()\n",
    "r = np.log(p/q)\n",
    "b = np.log((y==1).mean() / (y==0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2560, 20001)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 20001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20001)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2560x20001 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 352524 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2560, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_term_doc @ r.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-10.22232],\n",
       "        [ -3.28149],\n",
       "        [ -7.90024],\n",
       "        ...,\n",
       "        [  8.47319],\n",
       "        [  8.31353],\n",
       "        [ 10.08913]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc @ r.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80625"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_term_doc @ r.T + b\n",
    "preds = pre_preds.T>0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_preds = val_term_doc @ np.stack([np.log(p), np.log(q)]).T + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ -897.68999,  -887.46767],\n",
       "        [-1821.03818, -1817.75669],\n",
       "        [ -308.38326,  -300.48302],\n",
       "        ...,\n",
       "        [ -952.47611,  -960.9493 ],\n",
       "        [-1016.18753, -1024.50106],\n",
       "        [ -705.86977,  -715.95891]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80625"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pre_preds.T[0] > pre_preds.T[1]\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_term_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x20001 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 115 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = val_term_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20001)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '>',\n",
       " 'a',\n",
       " 'adult',\n",
       " 'agent',\n",
       " 'ahead',\n",
       " 'an',\n",
       " 'and',\n",
       " 'anderson',\n",
       " 'any',\n",
       " 'as',\n",
       " 'at',\n",
       " 'awful',\n",
       " 'bad',\n",
       " 'begin',\n",
       " 'being',\n",
       " 'best',\n",
       " 'between',\n",
       " 'block',\n",
       " 'boring',\n",
       " 'br',\n",
       " 'brings',\n",
       " 'but',\n",
       " 'called',\n",
       " 'cartoon',\n",
       " 'cartoons',\n",
       " 'city',\n",
       " 'clever',\n",
       " 'complete',\n",
       " 'concept',\n",
       " 'decent',\n",
       " 'disappointment',\n",
       " 'down',\n",
       " 'duck',\n",
       " 'episodes',\n",
       " 'even',\n",
       " 'failure',\n",
       " 'first',\n",
       " 'for',\n",
       " 'from',\n",
       " 'funny',\n",
       " 'gags',\n",
       " 'gary',\n",
       " 'good',\n",
       " 'goofy',\n",
       " 'gross',\n",
       " 'her',\n",
       " 'homage',\n",
       " 'if',\n",
       " 'is',\n",
       " 'its',\n",
       " 'just',\n",
       " 'lacked',\n",
       " 'like',\n",
       " 'make',\n",
       " 'mediocre',\n",
       " 'men',\n",
       " 'mostly',\n",
       " 'neither',\n",
       " 'network',\n",
       " 'new',\n",
       " 'of',\n",
       " 'one',\n",
       " 'or',\n",
       " 'other',\n",
       " 'out',\n",
       " 'pamela',\n",
       " 'period',\n",
       " 'plain',\n",
       " 'plot',\n",
       " 'pretty',\n",
       " 'rat',\n",
       " 'real',\n",
       " 'rebirth',\n",
       " 's',\n",
       " 'saves',\n",
       " 'see',\n",
       " 'seems',\n",
       " 'series',\n",
       " 'sexy',\n",
       " 'she',\n",
       " 'shock',\n",
       " 'so',\n",
       " 'some',\n",
       " 'spoilers',\n",
       " 'spoof',\n",
       " 'spoofs',\n",
       " 'suffered',\n",
       " 'superhero',\n",
       " 'superior',\n",
       " 'taped',\n",
       " 'the',\n",
       " 'this',\n",
       " 'those',\n",
       " 'tick',\n",
       " 'to',\n",
       " 'tries',\n",
       " 'unwatchable',\n",
       " 'wacky',\n",
       " 'was',\n",
       " 'watch',\n",
       " 'what',\n",
       " 'wit',\n",
       " 'with',\n",
       " 'without',\n",
       " 'writing',\n",
       " 'your']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab[index] for index, i in enumerate(xx.toarray()[0]) if i > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for index, i in enumerate(xx.toarray()[0]):\n",
    "    if i:\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we can fit logistic regression where the features are the unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._logistic.LogisticRegression"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.828515625"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1e8, dual=False, max_iter=1000)\n",
    "m.fit(x, y)\n",
    "preds = m.predict(val_term_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the regularized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831640625"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1.0, dual=False, max_iter=1000)\n",
    "m.fit(x, y)\n",
    "preds = m.predict(val_term_doc)\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.nlp import *\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNB(nn.Module):\n",
    "    def __init__(self, nf, ny):\n",
    "        super().__init__()\n",
    "        self.w = nn.Embedding(nf, ny)\n",
    "        # self.w = nn.Embedding(nf+1, ny)\n",
    "        # self.w.weight.data.uniform_(-1, 1)\n",
    "        self.w.weight.data = torch.FloatTensor(r.tolist()[0])\n",
    "        self.w.weight.data = self.w.weight.data.reshape(-1, 1)\n",
    "        # self.r = nn.Embedding(nf, ny)\n",
    "        \n",
    "    def forward(self, feat_idx):\n",
    "        # self.w.weight.data[0] = 0\n",
    "        idx = feat_idx - 1\n",
    "        idx2 = [a for a in idx if a >= 0]\n",
    "        idx3 = np.array(idx2)\n",
    "        v = self.w(V(idx3))\n",
    "        # r = self.r(feat_idx)\n",
    "        # x = ((w+self.w_adj)*r/self.r_adj).sum(1)\n",
    "        # x = w*r\n",
    "        x = v.sum(1)\n",
    "        # return F.softmax(x)\n",
    "        # return x.reshape(1, -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(pred, y):\n",
    "    # y2 = torch.max(y,axis=1)[0]\n",
    "    y2 = np.argmax(y)\n",
    "    p = torch.exp(pred) / (1+torch.exp(pred))\n",
    "    result = torch.mean(-(y2 * torch.log(p) + (1-y2)*torch.log(1-p)))\n",
    "    # return result.reshape(1, -1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20001)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20001"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3 = MySimpleNB(len(vocab), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20001, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net3.w.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20001)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20001"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl=val_term_doc.shape[1]\n",
    "sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl=val_term_doc.shape[1]\n",
    "md = TextClassifierData.from_bow(\n",
    "    trn_term_doc, trn_y,\n",
    "    val_term_doc, val_y,\n",
    "    200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??TextClassifierData.from_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 20001)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "net4 = MySimpleNB(len(vocab), 1)\n",
    "# loss = nn.NLLLoss()\n",
    "# loss = torch.nn.CrossEntropyLoss()\n",
    "loss = binary_loss\n",
    "lr = 1e-2\n",
    "losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-9.0411e-04],\n",
       "        [-6.0760e-02],\n",
       "        [ 1.6750e-01],\n",
       "        ...,\n",
       "        [ 7.0650e-01],\n",
       "        [ 1.1120e+00],\n",
       "        [ 7.0650e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4.w.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = md.trn_ds[ii]\n",
    "ii = ii + 1\n",
    "xt, _a, _b, yt = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     2,\n",
       "            7,    12,    13,    14,    15,   117,   290,   292,   298,   337,   449,   450,   467,   633,\n",
       "          895,   947,  1218,  1302,  1748,  1889,  1906,  1911,  2140,  2202,  2293,  2296,  2627,  2644,\n",
       "         2694,  2716,  2718,  2984,  3031,  3053,  3358,  3506,  3578,  3630,  4079,  4128,  4230,  4267,\n",
       "         4289,  4389,  4606,  4864,  4881,  5004,  5070,  5077,  5351,  5371,  5833,  6444,  6633,  6651,\n",
       "         6761,  6786,  6961,  7011,  7217,  7218,  7618,  7635,  8112,  8158,  8188,  8326,  8628,  8635,\n",
       "         8801,  8952,  9451,  9474,  9572,  9849,  9979,  9983, 10132, 10363, 10381, 10551, 10559, 10747,\n",
       "        10796, 11051, 11253, 11367, 11558, 11719, 11732, 11846, 12058, 12076, 12152, 12220, 12245, 12389,\n",
       "        12460, 12463, 12524, 12592, 12914, 13592, 14293, 14381, 14794, 15020, 15271, 15352, 15796, 15807,\n",
       "        16023, 16074, 16503, 16738, 16851, 16935, 17526, 17562, 17711, 17816, 17820, 17871, 17887, 17917,\n",
       "        17931, 17983, 18024, 18035, 18224, 19021, 19068, 19320, 19337, 19374, 19467, 19483, 19494, 19526,\n",
       "        19651, 19668, 19719, 19884]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 145,\n",
       " array([1., 0.], dtype=float32))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), 20001)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape, len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trades', 20001)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[18178], len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            1,     7,     8,     9,    12,    14,    15,    23,    24,    66,   152,   153,   154,   194,\n",
       "          265,   290,   292,   298,   322,   540,   693,   737,   895,  1117,  1168,  1218,  1237,  1302,\n",
       "         1713,  1764,  1803,  1817,  1943,  1953,  2296,  2451,  2600,  2873,  2990,  3177,  3583,  4094,\n",
       "         4158,  4460,  4873,  5006,  5653,  6004,  6063,  6083,  6237,  6391,  6460,  6470,  6546,  6553,\n",
       "         6633,  6649,  6662,  6761,  6829,  6876,  6957,  7011,  7115,  7413,  7419,  7639,  7974,  8103,\n",
       "         8186,  8208,  8433,  8505,  8752,  8801,  8952,  9451,  9459,  9474,  9483,  9572,  9675,  9749,\n",
       "         9833,  9979, 10071, 10171, 10236, 10381, 10559, 10618, 10730, 10747, 11141, 11371, 11570, 11719,\n",
       "        11740, 11831, 12220, 12328, 12389, 12427, 12435, 12460, 12463, 12524, 12607, 12732, 12986, 12987,\n",
       "        13692, 14310, 15271, 15411, 15584, 15678, 15679, 15784, 15785, 16133, 16138, 16257, 16439, 16482,\n",
       "        16499, 16531, 16534, 16657, 16979, 17526, 17563, 17816, 17820, 17836, 17838, 17858, 17887, 17948,\n",
       "        18035, 18082, 18171, 18221, 18329, 18868, 19277, 19320, 19374, 19431, 19444, 19459, 19492, 19498,\n",
       "        19526, 19651, 19755, 19850]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 158,\n",
       " array([1., 0.], dtype=float32))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.trn_ds[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "'\n",
      ",\n",
      "-\n",
      ".\n",
      "/\n",
      "1970s\n",
      "<\n",
      ">\n",
      "a\n",
      "about\n",
      "actors\n",
      "actress\n",
      "adapted\n",
      "ago\n",
      "and\n",
      "ann\n",
      "as\n",
      "at\n",
      "because\n",
      "best\n",
      "better\n",
      "between\n",
      "body\n",
      "book\n",
      "boyle\n",
      "br\n",
      "by\n",
      "cable\n",
      "camera\n",
      "can\n",
      "canadian\n",
      "center\n",
      "chance\n",
      "character\n",
      "clearly\n",
      "col\n",
      "combined\n",
      "commercials\n",
      "cosmetic\n",
      "course\n",
      "creepiness\n",
      "critical\n",
      "cross\n",
      "curve\n",
      "decided\n",
      "deserved\n",
      "desperate\n",
      "did\n",
      "directed\n",
      "director\n",
      "door\n",
      "dose\n",
      "else\n",
      "eyebrows\n",
      "features\n",
      "feeling\n",
      "film\n",
      "find\n",
      "flynn\n",
      "for\n",
      "from\n",
      "front\n",
      "goes\n",
      "gone\n",
      "hardly\n",
      "has\n",
      "having\n",
      "her\n",
      "house\n",
      "houswives\n",
      "if\n",
      "in\n",
      "is\n",
      "it\n",
      "jeff\n",
      "kennedy\n",
      "know\n",
      "known\n",
      "lara\n",
      "lifetime\n",
      "like\n",
      "long\n",
      "look\n",
      "made\n",
      "mainly\n",
      "material\n",
      "mention\n",
      "mild\n",
      "moments\n",
      "movie\n",
      "ms\n",
      "mystery\n",
      "new\n",
      "next\n",
      "no\n",
      "not\n",
      "novel\n",
      "of\n",
      "on\n",
      "one\n",
      "or\n",
      "other\n",
      "parts\n",
      "precede\n",
      "read\n",
      "recognizable\n",
      "rest\n",
      "rivers\n",
      "s\n",
      "same\n",
      "serves\n",
      "setting\n",
      "showed\n",
      "siddons\n",
      "someone\n",
      "sports\n",
      "star\n",
      "stepford\n",
      "t\n",
      "take\n",
      "television\n",
      "that\n",
      "the\n",
      "thing\n",
      "this\n",
      "threw\n",
      "through\n",
      "time\n",
      "title\n",
      "to\n",
      "transformation\n",
      "version\n",
      "viewer\n",
      "was\n",
      "watched\n",
      "we\n",
      "what\n",
      "when\n",
      "which\n",
      "who\n",
      "with\n",
      "wives\n",
      "woolnough\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "for index, idx in enumerate(to_np(xt)):\n",
    "    if idx:\n",
    "        print(vocab[idx-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('!', 20001)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[0], len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     2,\n",
       "           7,    12,    13,    14,    15,   117,   290,   292,   298,   337,   449,   450,   467,   633,\n",
       "         895,   947,  1218,  1302,  1748,  1889,  1906,  1911,  2140,  2202,  2293,  2296,  2627,  2644,\n",
       "        2694,  2716,  2718,  2984,  3031,  3053,  3358,  3506,  3578,  3630,  4079,  4128,  4230,  4267,\n",
       "        4289,  4389,  4606,  4864,  4881,  5004,  5070,  5077,  5351,  5371,  5833,  6444,  6633,  6651,\n",
       "        6761,  6786,  6961,  7011,  7217,  7218,  7618,  7635,  8112,  8158,  8188,  8326,  8628,  8635,\n",
       "        8801,  8952,  9451,  9474,  9572,  9849,  9979,  9983, 10132, 10363, 10381, 10551, 10559, 10747,\n",
       "       10796, 11051, 11253, 11367, 11558, 11719, 11732, 11846, 12058, 12076, 12152, 12220, 12245, 12389,\n",
       "       12460, 12463, 12524, 12592, 12914, 13592, 14293, 14381, 14794, 15020, 15271, 15352, 15796, 15807,\n",
       "       16023, 16074, 16503, 16738, 16851, 16935, 17526, 17562, 17711, 17816, 17820, 17871, 17887, 17917,\n",
       "       17931, 17983, 18024, 18035, 18224, 19021, 19068, 19320, 19337, 19374, 19467, 19483, 19494, 19526,\n",
       "       19651, 19668, 19719, 19884])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.0486, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4.w(V(xt)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0608, -0.0324,  0.0052, -0.0278,  0.0086, -0.0434, -1.0853, -0.0374,\n",
      "        -0.0321, -0.0027, -0.0833,  0.0133,  0.1957,  0.4188, -0.1834,  0.0295,\n",
      "         0.0133,  0.0537, -0.0744, -0.0341,  0.7328, -0.3003,  0.1957, -0.2098,\n",
      "        -0.0473,  0.0133, -0.0322,  0.0274, -1.4907, -0.4975,  0.0210,  1.1120,\n",
      "         0.3700,  0.1777,  0.1321, -0.3496,  0.4188,  0.0133,  0.9296, -0.6798,\n",
      "         0.4188, -0.6798,  0.4188,  0.1957, -0.6798, -0.7243,  0.0133,  0.7065,\n",
      "        -0.1837,  0.0461, -0.2878, -1.0365, -0.4975, -0.4627, -1.3729,  0.5242,\n",
      "        -0.3775, -0.0317,  0.0934,  0.5242, -0.0437,  0.0400,  0.1564, -0.2335,\n",
      "        -0.0776, -0.4975,  0.0490, -0.0722, -0.0344, -0.1739, -0.6798, -0.1993,\n",
      "         0.0222,  0.0391,  0.0116, -0.5744,  0.2365, -0.1645,  0.6459,  0.0133,\n",
      "         0.1957, -0.1637, -0.1060, -0.3544, -0.3549, -0.4285, -0.3661, -0.4662,\n",
      "        -1.2394,  0.1134, -0.1883, -0.3231,  0.5634,  0.3971, -0.4022, -0.4183,\n",
      "        -0.1570,  0.2140, -0.0063, -0.0875, -0.0399, -0.1919,  0.0020,  0.6064,\n",
      "        -0.6798, -0.3921, -0.2743, -0.3661,  0.0133,  0.0155,  0.1981, -0.8339,\n",
      "        -0.0556, -0.4285, -0.6798, -0.5319,  0.2647,  0.5422, -0.6798, -0.2092,\n",
      "        -0.1616,  0.3647, -0.0457,  0.0102, -0.2332, -0.0588, -0.6798, -0.2954,\n",
      "         0.0393, -0.4035, -0.0198, -0.2743, -0.0533,  0.3551, -0.1156, -0.0311,\n",
      "         0.0590, -0.1275,  0.0404, -0.0755,  0.0236,  0.0310, -0.2743, -0.6798,\n",
      "        -0.0240], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "y_pred = net4(V(xt))\n",
    "print(y_pred)\n",
    "l = binary_loss(y_pred, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0608, -0.0324,  0.0052, -0.0278,  0.0086, -0.0434, -1.0853, -0.0374,\n",
       "        -0.0321, -0.0027, -0.0833,  0.0133,  0.1957,  0.4188, -0.1834,  0.0295,\n",
       "         0.0133,  0.0537, -0.0744, -0.0341,  0.7328, -0.3003,  0.1957, -0.2098,\n",
       "        -0.0473,  0.0133, -0.0322,  0.0274, -1.4907, -0.4975,  0.0210,  1.1120,\n",
       "         0.3700,  0.1777,  0.1321, -0.3496,  0.4188,  0.0133,  0.9296, -0.6798,\n",
       "         0.4188, -0.6798,  0.4188,  0.1957, -0.6798, -0.7243,  0.0133,  0.7065,\n",
       "        -0.1837,  0.0461, -0.2878, -1.0365, -0.4975, -0.4627, -1.3729,  0.5242,\n",
       "        -0.3775, -0.0317,  0.0934,  0.5242, -0.0437,  0.0400,  0.1564, -0.2335,\n",
       "        -0.0776, -0.4975,  0.0490, -0.0722, -0.0344, -0.1739, -0.6798, -0.1993,\n",
       "         0.0222,  0.0391,  0.0116, -0.5744,  0.2365, -0.1645,  0.6459,  0.0133,\n",
       "         0.1957, -0.1637, -0.1060, -0.3544, -0.3549, -0.4285, -0.3661, -0.4662,\n",
       "        -1.2394,  0.1134, -0.1883, -0.3231,  0.5634,  0.3971, -0.4022, -0.4183,\n",
       "        -0.1570,  0.2140, -0.0063, -0.0875, -0.0399, -0.1919,  0.0020,  0.6064,\n",
       "        -0.6798, -0.3921, -0.2743, -0.3661,  0.0133,  0.0155,  0.1981, -0.8339,\n",
       "        -0.0556, -0.4285, -0.6798, -0.5319,  0.2647,  0.5422, -0.6798, -0.2092,\n",
       "        -0.1616,  0.3647, -0.0457,  0.0102, -0.2332, -0.0588, -0.6798, -0.2954,\n",
       "         0.0393, -0.4035, -0.0198, -0.2743, -0.0533,  0.3551, -0.1156, -0.0311,\n",
       "         0.0590, -0.1275,  0.0404, -0.0755,  0.0236,  0.0310, -0.2743, -0.6798,\n",
       "        -0.0240], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(net4.w.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_a.shape, _a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(0.0033) tensor([-0.0608])\n",
      "6 tensor(0.0034) tensor([-0.0324])\n",
      "11 tensor(0.0035) tensor([0.0052])\n",
      "12 tensor(0.0034) tensor([-0.0278])\n",
      "13 tensor(0.0035) tensor([0.0086])\n",
      "14 tensor(0.0034) tensor([-0.0434])\n",
      "116 tensor(0.0017) tensor([-1.0853])\n",
      "289 tensor(0.0034) tensor([-0.0374])\n",
      "291 tensor(0.0034) tensor([-0.0321])\n",
      "297 tensor(0.0034) tensor([-0.0027])\n",
      "336 tensor(0.0033) tensor([-0.0833])\n",
      "448 tensor(0.0035) tensor([0.0133])\n",
      "449 tensor(0.0038) tensor([0.1957])\n",
      "466 tensor(0.0042) tensor([0.4188])\n",
      "632 tensor(0.0031) tensor([-0.1834])\n",
      "894 tensor(0.0035) tensor([0.0295])\n",
      "946 tensor(0.0035) tensor([0.0133])\n",
      "1217 tensor(0.0035) tensor([0.0537])\n",
      "1301 tensor(0.0033) tensor([-0.0744])\n",
      "1747 tensor(0.0034) tensor([-0.0341])\n",
      "1888 tensor(0.0047) tensor([0.7328])\n",
      "1905 tensor(0.0029) tensor([-0.3003])\n",
      "1910 tensor(0.0038) tensor([0.1957])\n",
      "2139 tensor(0.0031) tensor([-0.2098])\n",
      "2201 tensor(0.0034) tensor([-0.0473])\n",
      "2292 tensor(0.0035) tensor([0.0133])\n",
      "2295 tensor(0.0034) tensor([-0.0322])\n",
      "2626 tensor(0.0035) tensor([0.0274])\n",
      "2643 tensor(0.0013) tensor([-1.4907])\n",
      "2693 tensor(0.0026) tensor([-0.4975])\n",
      "2715 tensor(0.0035) tensor([0.0210])\n",
      "2717 tensor(0.0052) tensor([1.1120])\n",
      "2983 tensor(0.0041) tensor([0.3700])\n",
      "3030 tensor(0.0038) tensor([0.1777])\n",
      "3052 tensor(0.0037) tensor([0.1321])\n",
      "3357 tensor(0.0029) tensor([-0.3496])\n",
      "3505 tensor(0.0042) tensor([0.4188])\n",
      "3577 tensor(0.0035) tensor([0.0133])\n",
      "3629 tensor(0.0049) tensor([0.9296])\n",
      "4078 tensor(0.0023) tensor([-0.6798])\n",
      "4127 tensor(0.0042) tensor([0.4188])\n",
      "4229 tensor(0.0023) tensor([-0.6798])\n",
      "4266 tensor(0.0042) tensor([0.4188])\n",
      "4288 tensor(0.0038) tensor([0.1957])\n",
      "4388 tensor(0.0023) tensor([-0.6798])\n",
      "4605 tensor(0.0023) tensor([-0.7243])\n",
      "4863 tensor(0.0035) tensor([0.0133])\n",
      "4880 tensor(0.0046) tensor([0.7065])\n",
      "5003 tensor(0.0031) tensor([-0.1837])\n",
      "5069 tensor(0.0035) tensor([0.0461])\n",
      "5076 tensor(0.0030) tensor([-0.2878])\n",
      "5350 tensor(0.0018) tensor([-1.0365])\n",
      "5370 tensor(0.0026) tensor([-0.4975])\n",
      "5832 tensor(0.0027) tensor([-0.4627])\n",
      "6443 tensor(0.0014) tensor([-1.3729])\n",
      "6632 tensor(0.0043) tensor([0.5242])\n",
      "6650 tensor(0.0028) tensor([-0.3775])\n",
      "6760 tensor(0.0034) tensor([-0.0317])\n",
      "6785 tensor(0.0036) tensor([0.0934])\n",
      "6960 tensor(0.0043) tensor([0.5242])\n",
      "7010 tensor(0.0034) tensor([-0.0437])\n",
      "7216 tensor(0.0035) tensor([0.0400])\n",
      "7217 tensor(0.0037) tensor([0.1564])\n",
      "7617 tensor(0.0030) tensor([-0.2335])\n",
      "7634 tensor(0.0033) tensor([-0.0776])\n",
      "8111 tensor(0.0026) tensor([-0.4975])\n",
      "8157 tensor(0.0035) tensor([0.0490])\n",
      "8187 tensor(0.0033) tensor([-0.0722])\n",
      "8325 tensor(0.0034) tensor([-0.0344])\n",
      "8627 tensor(0.0031) tensor([-0.1739])\n",
      "8634 tensor(0.0023) tensor([-0.6798])\n",
      "8800 tensor(0.0031) tensor([-0.1993])\n",
      "8951 tensor(0.0035) tensor([0.0222])\n",
      "9450 tensor(0.0035) tensor([0.0391])\n",
      "9473 tensor(0.0035) tensor([0.0116])\n",
      "9571 tensor(0.0025) tensor([-0.5744])\n",
      "9848 tensor(0.0039) tensor([0.2365])\n",
      "9978 tensor(0.0032) tensor([-0.1645])\n",
      "9982 tensor(0.0045) tensor([0.6459])\n",
      "10131 tensor(0.0035) tensor([0.0133])\n",
      "10362 tensor(0.0038) tensor([0.1957])\n",
      "10380 tensor(0.0032) tensor([-0.1637])\n",
      "10550 tensor(0.0033) tensor([-0.1060])\n",
      "10558 tensor(0.0028) tensor([-0.3544])\n",
      "10746 tensor(0.0028) tensor([-0.3549])\n",
      "10795 tensor(0.0027) tensor([-0.4285])\n",
      "11050 tensor(0.0028) tensor([-0.3661])\n",
      "11252 tensor(0.0027) tensor([-0.4662])\n",
      "11366 tensor(0.0015) tensor([-1.2394])\n",
      "11557 tensor(0.0036) tensor([0.1134])\n",
      "11718 tensor(0.0031) tensor([-0.1883])\n",
      "11731 tensor(0.0029) tensor([-0.3231])\n",
      "11845 tensor(0.0044) tensor([0.5634])\n",
      "12057 tensor(0.0041) tensor([0.3971])\n",
      "12075 tensor(0.0028) tensor([-0.4022])\n",
      "12151 tensor(0.0027) tensor([-0.4183])\n",
      "12219 tensor(0.0032) tensor([-0.1570])\n",
      "12244 tensor(0.0038) tensor([0.2140])\n",
      "12388 tensor(0.0034) tensor([-0.0063])\n",
      "12459 tensor(0.0033) tensor([-0.0875])\n",
      "12462 tensor(0.0034) tensor([-0.0399])\n",
      "12523 tensor(0.0031) tensor([-0.1919])\n",
      "12591 tensor(0.0035) tensor([0.0020])\n",
      "12913 tensor(0.0045) tensor([0.6064])\n",
      "13591 tensor(0.0023) tensor([-0.6798])\n",
      "14292 tensor(0.0028) tensor([-0.3921])\n",
      "14380 tensor(0.0030) tensor([-0.2743])\n",
      "14793 tensor(0.0028) tensor([-0.3661])\n",
      "15019 tensor(0.0035) tensor([0.0133])\n",
      "15270 tensor(0.0035) tensor([0.0155])\n",
      "15351 tensor(0.0038) tensor([0.1981])\n",
      "15795 tensor(0.0021) tensor([-0.8339])\n",
      "15806 tensor(0.0034) tensor([-0.0556])\n",
      "16022 tensor(0.0027) tensor([-0.4285])\n",
      "16073 tensor(0.0023) tensor([-0.6798])\n",
      "16502 tensor(0.0026) tensor([-0.5319])\n",
      "16737 tensor(0.0039) tensor([0.2647])\n",
      "16850 tensor(0.0044) tensor([0.5422])\n",
      "16934 tensor(0.0023) tensor([-0.6798])\n",
      "17525 tensor(0.0031) tensor([-0.2092])\n",
      "17561 tensor(0.0032) tensor([-0.1616])\n",
      "17710 tensor(0.0041) tensor([0.3647])\n",
      "17815 tensor(0.0034) tensor([-0.0457])\n",
      "17819 tensor(0.0035) tensor([0.0102])\n",
      "17870 tensor(0.0030) tensor([-0.2332])\n",
      "17886 tensor(0.0033) tensor([-0.0588])\n",
      "17916 tensor(0.0023) tensor([-0.6798])\n",
      "17930 tensor(0.0029) tensor([-0.2954])\n",
      "17982 tensor(0.0035) tensor([0.0393])\n",
      "18023 tensor(0.0028) tensor([-0.4035])\n",
      "18034 tensor(0.0034) tensor([-0.0198])\n",
      "18223 tensor(0.0030) tensor([-0.2743])\n",
      "19020 tensor(0.0034) tensor([-0.0533])\n",
      "19067 tensor(0.0041) tensor([0.3551])\n",
      "19319 tensor(0.0032) tensor([-0.1156])\n",
      "19336 tensor(0.0034) tensor([-0.0311])\n",
      "19373 tensor(0.0035) tensor([0.0590])\n",
      "19466 tensor(0.0032) tensor([-0.1275])\n",
      "19482 tensor(0.0035) tensor([0.0404])\n",
      "19493 tensor(0.0033) tensor([-0.0755])\n",
      "19525 tensor(0.0035) tensor([0.0236])\n",
      "19650 tensor(0.0035) tensor([0.0310])\n",
      "19667 tensor(0.0030) tensor([-0.2743])\n",
      "19718 tensor(0.0023) tensor([-0.6798])\n",
      "19883 tensor(0.0034) tensor([-0.0240])\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(net4.w.weight.grad.data):\n",
    "    for j in i:\n",
    "        if j != 0:\n",
    "            print(idx, j, net4.w.weight.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "net4.w.weight.data -= net4.w.weight.grad.data * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.0411e-04],\n",
       "        [-6.0793e-02],\n",
       "        [ 1.6750e-01],\n",
       "        ...,\n",
       "        [ 7.0650e-01],\n",
       "        [ 1.1120e+00],\n",
       "        [ 7.0650e-01]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4.w.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0033],\n",
       "        [0.0000],\n",
       "        ...,\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4.w.weight.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0033)\n",
      "tensor(0.0034)\n",
      "tensor(0.0035)\n",
      "tensor(0.0034)\n",
      "tensor(0.0035)\n",
      "tensor(0.0034)\n",
      "tensor(0.0017)\n",
      "tensor(0.0034)\n",
      "tensor(0.0034)\n",
      "tensor(0.0034)\n",
      "tensor(0.0033)\n",
      "tensor(0.0035)\n",
      "tensor(0.0038)\n",
      "tensor(0.0042)\n",
      "tensor(0.0031)\n",
      "tensor(0.0035)\n",
      "tensor(0.0035)\n",
      "tensor(0.0035)\n",
      "tensor(0.0033)\n",
      "tensor(0.0034)\n",
      "tensor(0.0047)\n",
      "tensor(0.0029)\n",
      "tensor(0.0038)\n",
      "tensor(0.0031)\n",
      "tensor(0.0034)\n",
      "tensor(0.0035)\n",
      "tensor(0.0034)\n",
      "tensor(0.0035)\n",
      "tensor(0.0013)\n",
      "tensor(0.0026)\n",
      "tensor(0.0035)\n",
      "tensor(0.0052)\n",
      "tensor(0.0041)\n",
      "tensor(0.0038)\n",
      "tensor(0.0037)\n",
      "tensor(0.0029)\n",
      "tensor(0.0042)\n",
      "tensor(0.0035)\n",
      "tensor(0.0049)\n",
      "tensor(0.0023)\n",
      "tensor(0.0042)\n",
      "tensor(0.0023)\n",
      "tensor(0.0042)\n",
      "tensor(0.0038)\n",
      "tensor(0.0023)\n",
      "tensor(0.0023)\n",
      "tensor(0.0035)\n",
      "tensor(0.0046)\n",
      "tensor(0.0031)\n",
      "tensor(0.0035)\n",
      "tensor(0.0030)\n",
      "tensor(0.0018)\n",
      "tensor(0.0026)\n",
      "tensor(0.0027)\n",
      "tensor(0.0014)\n",
      "tensor(0.0043)\n",
      "tensor(0.0028)\n",
      "tensor(0.0034)\n",
      "tensor(0.0036)\n",
      "tensor(0.0043)\n",
      "tensor(0.0034)\n",
      "tensor(0.0035)\n",
      "tensor(0.0037)\n",
      "tensor(0.0030)\n",
      "tensor(0.0033)\n",
      "tensor(0.0026)\n",
      "tensor(0.0035)\n",
      "tensor(0.0033)\n",
      "tensor(0.0034)\n",
      "tensor(0.0031)\n",
      "tensor(0.0023)\n",
      "tensor(0.0031)\n",
      "tensor(0.0035)\n",
      "tensor(0.0035)\n",
      "tensor(0.0035)\n",
      "tensor(0.0025)\n",
      "tensor(0.0039)\n",
      "tensor(0.0032)\n",
      "tensor(0.0045)\n",
      "tensor(0.0035)\n",
      "tensor(0.0038)\n",
      "tensor(0.0032)\n",
      "tensor(0.0033)\n",
      "tensor(0.0028)\n",
      "tensor(0.0028)\n",
      "tensor(0.0027)\n",
      "tensor(0.0028)\n",
      "tensor(0.0027)\n",
      "tensor(0.0015)\n",
      "tensor(0.0036)\n",
      "tensor(0.0031)\n",
      "tensor(0.0029)\n",
      "tensor(0.0044)\n",
      "tensor(0.0041)\n",
      "tensor(0.0028)\n",
      "tensor(0.0027)\n",
      "tensor(0.0032)\n",
      "tensor(0.0038)\n",
      "tensor(0.0034)\n",
      "tensor(0.0033)\n",
      "tensor(0.0034)\n",
      "tensor(0.0031)\n",
      "tensor(0.0035)\n",
      "tensor(0.0045)\n",
      "tensor(0.0023)\n",
      "tensor(0.0028)\n",
      "tensor(0.0030)\n",
      "tensor(0.0028)\n",
      "tensor(0.0035)\n",
      "tensor(0.0035)\n",
      "tensor(0.0038)\n",
      "tensor(0.0021)\n",
      "tensor(0.0034)\n",
      "tensor(0.0027)\n",
      "tensor(0.0023)\n",
      "tensor(0.0026)\n",
      "tensor(0.0039)\n",
      "tensor(0.0044)\n",
      "tensor(0.0023)\n",
      "tensor(0.0031)\n",
      "tensor(0.0032)\n",
      "tensor(0.0041)\n",
      "tensor(0.0034)\n",
      "tensor(0.0035)\n",
      "tensor(0.0030)\n",
      "tensor(0.0033)\n",
      "tensor(0.0023)\n",
      "tensor(0.0029)\n",
      "tensor(0.0035)\n",
      "tensor(0.0028)\n",
      "tensor(0.0034)\n",
      "tensor(0.0030)\n",
      "tensor(0.0034)\n",
      "tensor(0.0041)\n",
      "tensor(0.0032)\n",
      "tensor(0.0034)\n",
      "tensor(0.0035)\n",
      "tensor(0.0032)\n",
      "tensor(0.0035)\n",
      "tensor(0.0033)\n",
      "tensor(0.0035)\n",
      "tensor(0.0035)\n",
      "tensor(0.0030)\n",
      "tensor(0.0023)\n",
      "tensor(0.0034)\n"
     ]
    }
   ],
   "source": [
    "for i in net4.w.weight.grad.data:\n",
    "    for j in i:\n",
    "        if j != 0:\n",
    "            print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4.w.weight.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, a2, a3, a4 = md.trn_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     2,     7,    12,    14,   298,   448,\n",
       "         455,   737,   774,   787,   809,   878,   895,  1218,  1302,  1748,  1764,  1934,  2304,  2543,\n",
       "        3037,  3244,  3255,  3440,  3845,  4538,  5006,  5137,  5301,  6220,  6525,  6528,  6571,  6703,\n",
       "        7011,  7037,  7180,  7195,  8188,  8386,  8507,  8586,  8640,  8655,  8752,  8883,  8925,  8952,\n",
       "        9451,  9474, 10249, 10477, 10597, 10747, 11141, 11719, 11831, 12107, 12181, 12251, 12389, 12460,\n",
       "       12463, 13058, 13740, 14439, 14776, 15045, 15086, 15271, 15521, 15671, 15800, 16439, 16881, 17143,\n",
       "       17246, 17526, 17816, 17820, 17863, 17873, 17887, 17899, 17983, 18035, 18398, 19178, 19320, 19337,\n",
       "       19467, 19483, 19691, 19692])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0.], dtype=float32), 0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a4, np.argmax(a4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(V(a4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6429, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(net4(V(a1)), V(a4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0608, -0.0325,  0.0052,  0.0086, -0.0027,  0.3953, -0.2895, -0.0344,\n",
       "        -0.0332,  0.3114,  0.0133,  0.0294,  0.0294,  0.0536, -0.0745, -0.0342,\n",
       "        -0.2027, -1.0853, -0.9029, -1.3158,  0.0133, -0.1690, -0.4975, -1.2394,\n",
       "        -1.0853,  0.1267, -0.3107, -0.4975, -0.7716, -0.2549,  0.6345, -0.0354,\n",
       "        -1.0853, -0.1014, -0.0437, -0.1492, -0.3921,  0.1629, -0.0722,  0.2575,\n",
       "         0.2247, -0.3231, -0.2125,  0.1311, -0.0892,  0.7065,  0.0934,  0.0222,\n",
       "         0.0391,  0.0116, -0.1767,  0.2422,  0.0913, -0.3550, -0.1699, -0.1884,\n",
       "         0.0565, -0.2685, -0.9481, -0.0162, -0.0063, -0.0875, -0.0399, -0.2002,\n",
       "        -0.1873,  0.2365,  0.2365,  0.2044,  0.6683,  0.0155, -0.3284,  0.1462,\n",
       "         0.0133, -0.1759, -0.1408,  0.0133, -0.0763, -0.2093, -0.0457,  0.0102,\n",
       "        -0.2287,  0.1257, -0.0589, -0.0846,  0.0393, -0.0199, -0.2790, -1.7784,\n",
       "        -0.1157, -0.0311, -0.1275,  0.0403, -0.1808, -1.0853],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4(V(a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score2(x, y):\n",
    "    y_pred = to_np(net2(V(x)))\n",
    "    return np.sum(y_pred.argmax(axis=1) == to_np(y).argmax(axis=1))/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x, y):\n",
    "    # print(f'x={x}, y={y}')\n",
    "    y_pred = to_np(net2(V(x))).sum() >= 0\n",
    "    # print(f'y_pred={y_pred}')\n",
    "    y2 = np.argmax(y)\n",
    "    # print(f'y2={y2}')\n",
    "    return np.sum(y_pred == y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 1, 5, 19, 55, 58, 865927)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = MySimpleNB(len(vocab), 1)\n",
    "# loss = nn.NLLLoss()\n",
    "# loss = torch.nn.CrossEntropyLoss()\n",
    "loss = binary_loss\n",
    "# lr = 1e-0\n",
    "lr = 1e-3\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list= []\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280, 20001, 1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net2.w(V(trn_term_doc.toarray()))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net2.w(V(trn_term_doc.toarray()))).sum(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-23.7094],\n",
       "        [-25.0861],\n",
       "        [-26.7620],\n",
       "        ...,\n",
       "        [-23.8291],\n",
       "        [-24.9664],\n",
       "        [-28.1986]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net2.w(V(trn_term_doc.toarray()))).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trn_term_doc @ r.T > 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-13.59826],\n",
       "        [-16.91834],\n",
       "        [-15.28112],\n",
       "        ...,\n",
       "        [ -2.12701],\n",
       "        [  1.68547],\n",
       "        [  9.05191]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc @ r.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-4d0c98d8e332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_term_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;31m# non-zeros is more important.  For now, raise an exception!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         raise TypeError(\"sparse matrix length is ambiguous; use getnnz()\"\n\u001b[0m\u001b[1;32m    296\u001b[0m                         \" or shape[0]\")\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "val_scores = []\n",
    "for t in tqdm(md.val_ds, total=len(trn_term_doc)):\n",
    "    x, _a, _b, y = t\n",
    "    val_scores.append(score(x,y))\n",
    "np.mean(to_np(val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = []\n",
    "for t in tqdm(md.val_ds, total=len(md.val_ds)):\n",
    "    x, _a, _b, y = t\n",
    "    val_scores.append(score(x,y))\n",
    "np.mean(to_np(val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filename = 'acc.txt'\n",
    "try:\n",
    "    os.remove(filename)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(md.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'lr={lr}')\n",
    "f = open(filename, 'a')\n",
    "\n",
    "for epoch in range(5):\n",
    "    print('')\n",
    "    print('epoch:', epoch)\n",
    "    print('time:', datetime.now())\n",
    "    loss_list = [0]\n",
    "    for index, t in tqdm(enumerate(md.trn_ds), total=len(md.trn_ds)):\n",
    "        xt, _a, _b, yt = t\n",
    "        y_pred = net2(V(xt))\n",
    "        l = loss(y_pred, V(yt))\n",
    "        # l = loss(yt, y_pred)\n",
    "        loss_list.append(l)\n",
    "        # print(f'{index}, {l}, {datetime.now().time()}')\n",
    "\n",
    "        # Backward pass: \n",
    "        # compute gradient of the loss with respect to \n",
    "        # model parameters\n",
    "        l.backward()\n",
    "        net2.w.weight.data -= net2.w.weight.grad.data * lr\n",
    "        # net2.b.data -= net2.b.grad.data * lr\n",
    "        \n",
    "        net2.w.weight.grad.data.zero_()\n",
    "        # net2.b.grad.data.zero_()   \n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        train_scores = []\n",
    "        for t in tqdm(md.trn_ds, total=len(md.trn_ds)):\n",
    "            x, _a, _b, y = t\n",
    "            train_scores.append(loss(net2(V(x)), V(y)))\n",
    "        l2 = np.mean(to_np(train_scores))\n",
    "        train_loss_list.append(l2)\n",
    "\n",
    "        val_scores = []\n",
    "        for t in tqdm(md.val_ds, total=len(md.val_ds)):\n",
    "            x, _a, _b, y = t\n",
    "            train_scores.append(loss(net2(V(x)), V(y)))\n",
    "        l3 = np.mean(to_np(train_scores))\n",
    "        val_loss_list.append(l3)\n",
    "                \n",
    "        val_scores = []\n",
    "        for t in tqdm(md.val_ds, total=len(md.val_ds)):\n",
    "            x, _a, _b, y = t\n",
    "            val_scores.append(score(x,y))\n",
    "        l4 = np.mean(to_np(val_scores))\n",
    "        val_acc_list.append(l4)\n",
    "\n",
    "        # print(f'epoch={epoch}, score={np.mean(val_scores)}')\n",
    "        print(f'epoch={epoch}, score={l2}')\n",
    "        print(f'epoch={epoch}, score={l3}')\n",
    "        print(f'epoch={epoch}, score={l4}')\n",
    "        f.write(f\"{l2}\\t{l3}\\t{l4}\\n\")\n",
    "        f.flush()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=len(train_loss_list)\n",
    "df = pd.DataFrame({\n",
    "    'train':train_loss_list[:length], \n",
    "    'valid':val_loss_list[:length],\n",
    "    'valid_acc':val_acc_list[:length]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_acc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:light",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
