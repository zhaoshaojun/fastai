{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.nlp import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/aclImdb/'\n",
    "names = ['neg','pos']\n",
    "names1 = ['neg', 'pos_']\n",
    "names2 = ['neg_', 'pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeledBow.feat \u001b[34mpos\u001b[m\u001b[m             unsupBow.feat   urls_pos.txt\r\n",
      "\u001b[34mneg\u001b[m\u001b[m             \u001b[34munsup\u001b[m\u001b[m           urls_neg.txt    urls_unsup.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls {PATH}train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn1,trn1_y = texts_labels_from_folders(f'{PATH}train',names1)\n",
    "val1,val1_y = texts_labels_from_folders(f'{PATH}test',names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn2,trn2_y = texts_labels_from_folders(f'{PATH}train',names2)\n",
    "val2,val2_y = texts_labels_from_folders(f'{PATH}test',names2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn1), len(trn1_y), len(trn2), len(trn2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val1), len(val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert (trn1_y==0).all()\n",
    "(trn1_y==0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert (trn1_y==0).all()\n",
    "(val1_y==0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert (trn2_y==1).all()\n",
    "(trn2_y==1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert (val2_y==1).all()\n",
    "(val2_y==1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_util(data, label, n):\n",
    "    assert len(data) == label.shape[0]\n",
    "    idx = np.random.choice(range(len(data)),n)\n",
    "    data_new = [data[i] for i in idx]\n",
    "    label_new = label[idx]\n",
    "    return data_new, label_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(data1, label1, data2, label2, n):\n",
    "    t1, t2 = sample_util(data1, label1, n)\n",
    "    t3, t4 = sample_util(data2, label2, n)\n",
    "    data = t1 + t3\n",
    "    label = np.concatenate((t2, t4))\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn, trn_y = sample(trn1, trn1_y, trn2, trn2_y, 64*100)\n",
    "# val, val_y = sample(val1, val1_y, val2, val2_y, 64*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn,trn_y = texts_labels_from_folders(f'{PATH}train',names)\n",
    "val,val_y = texts_labels_from_folders(f'{PATH}test',names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create vectors and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr = CountVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_term_doc = veczr.fit_transform(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_term_doc = veczr.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aussie', 'aussies', 'austen', 'austeniana', 'austens']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = veczr.get_feature_names(); vocab[5000:5005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x08\\x08\\x08\\x08a', '\\x10own', '!', '\"', '#']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_term_doc = trn_term_doc.sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_term_doc = val_term_doc.sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 75132), (25000, 75132))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape, val_term_doc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the **log-count ratio** $r$ for each word $f$:\n",
    "\n",
    "$r = \\log \\frac{\\text{ratio of feature $f$ in positive documents}}{\\text{ratio of feature $f$ in negative documents}}$\n",
    "\n",
    "where ratio of feature $f$ in positive documents is the number of times a positive document has a feature divided by the number of positive documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(y_i):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return p+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=trn_term_doc\n",
    "y=trn_y\n",
    "\n",
    "p = pr(1)/pr(1).sum()\n",
    "q = pr(0)/pr(0).sum()\n",
    "r = np.log(p/q)\n",
    "b = np.log((y==1).mean() / (y==0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 75132)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75132"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 75132)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 75132)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x75132 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3640465 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_term_doc @ r.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-5.25616],\n",
       "        [-3.41848],\n",
       "        [ 0.42768],\n",
       "        ...,\n",
       "        [68.81967],\n",
       "        [ 4.6196 ],\n",
       "        [ 3.74532]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc @ r.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82844"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds = val_term_doc @ r.T + b\n",
    "preds = pre_preds.T>0\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_preds = val_term_doc @ np.stack([np.log(p), np.log(q)]).T + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ -617.48225,  -612.22609],\n",
       "        [ -549.41436,  -545.99589],\n",
       "        [-1036.89288, -1037.32056],\n",
       "        ...,\n",
       "        [-4026.31409, -4095.13376],\n",
       "        [ -633.7084 ,  -638.328  ],\n",
       "        [ -508.107  ,  -511.85232]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82844"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pre_preds.T[0] > pre_preds.T[1]\n",
    "nb_score = (preds==val_y).mean()\n",
    "nb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_term_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x75132 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 83 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = val_term_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 75132)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we can fit logistic regression where the features are the unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._logistic.LogisticRegression"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85704"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1e8, dual=False, max_iter=1000)\n",
    "m.fit(x, y)\n",
    "preds = m.predict(val_term_doc)\n",
    "lr_score = (preds==val_y).mean()\n",
    "lr_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the regularized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87396"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=1.0, dual=False, max_iter=1000)\n",
    "m.fit(x, y)\n",
    "preds = m.predict(val_term_doc)\n",
    "lr_score2 = (preds==val_y).mean()\n",
    "lr_score2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(pred, y):\n",
    "    pred = pred.clamp(-10, 10)\n",
    "    # y2 = torch.max(y,axis=1)[0]\n",
    "    y2 = y\n",
    "    p = torch.exp(pred) / (1+torch.exp(pred))\n",
    "    result = torch.mean(-(y2 * torch.log(p) + (1-y2)*torch.log(1-p)))\n",
    "    # return result.reshape(1, -1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(pred, y):\n",
    "    return np.sum(to_np((pred > 0) == y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNB2(nn.Module):\n",
    "    def __init__(self, nf, ny):\n",
    "        super().__init__()\n",
    "        self.w = nn.Embedding(nf, ny)\n",
    "        # self.w = nn.Embedding(nf+1, ny)\n",
    "        # self.w.weight.data.uniform_(-1, 1)\n",
    "        self.w.weight.data = torch.FloatTensor(r)[0].reshape(-1,1)\n",
    "        # self.r = nn.Embedding(nf, ny)\n",
    "        \n",
    "    def forward(self, feat_idx):\n",
    "        idx = feat_idx.nonzero()[1]\n",
    "        v = self.w(V(idx))\n",
    "        x = v.sum()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_a = SimpleNB2(len(vocab),1)\n",
    "\n",
    "loss = binary_loss\n",
    "# loss = torch.nn.CrossEntropyLoss\n",
    "lr = 1e-2\n",
    "losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    8,    13,    15,    16,  1039,  1041,  1050,  3219,  3814,  4926,  6304,  7012,  8696,  8775,\n",
       "       10930, 15444, 24540, 24770, 25593, 26188, 28081, 34716, 40649, 46096, 46749, 46986, 47002, 57049,\n",
       "       59330, 61967, 61969, 63122, 63341, 65484, 66458, 66554, 66684, 67252, 69418, 72931, 73145, 73488,\n",
       "       73782], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = trn_term_doc[0].nonzero()[1]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9171, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_a.w(V(idx)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.8084, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_a(trn_term_doc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net_a(trn_term_doc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trn_y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5420e-05, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_loss(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(net_a(trn_term_doc[-1]), trn_y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[3.91715]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc[0] @ r.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[13.80843]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc[-1] @ r.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9171, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_a(trn_term_doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net_a(trn_term_doc[0]) > 0) == trn_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filename = 'acc.txt'\n",
    "try:\n",
    "    os.remove(filename)\n",
    "    print('removed')\n",
    "except:\n",
    "    print('pass')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = trn_term_doc[ii]\n",
    "_y = trn_y[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-10.8404, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_pred = net_a(_x)\n",
    "_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss(_y_pred, V(_y))\n",
    "# l = loss(yt, y_pred)\n",
    "# loss_list.append(l)\n",
    "# print(f'{index}, {l}, {datetime.now().time()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5420e-05, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5420e-05, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_a.w.weight.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_a.w.weight.data -= net_a.w.weight.grad.data * lr\n",
    "# net2.b.data -= net2.b.grad.data * lr\n",
    "\n",
    "net_a.w.weight.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6904],\n",
       "        [-0.6959],\n",
       "        [-0.0575],\n",
       "        ...,\n",
       "        [ 0.6904],\n",
       "        [-0.0028],\n",
       "        [-0.6959]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_a.w.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "train_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_a = SimpleNB2(len(vocab),1)\n",
    "\n",
    "loss = binary_loss\n",
    "# loss = torch.nn.CrossEntropyLoss\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:04<00:00, 5090.41it/s]\n",
      "0.90968\n"
     ]
    }
   ],
   "source": [
    "trn_scores = []\n",
    "for x, y in tqdm(zip(trn_term_doc, trn_y), total=trn_term_doc.shape[0]):\n",
    "    trn_scores.append(score(net_a(x),y))\n",
    "print(np.mean(to_np(trn_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:05<00:00, 4864.08it/s]\n",
      "0.82844\n"
     ]
    }
   ],
   "source": [
    "val_scores = []\n",
    "for x, y in tqdm(zip(val_term_doc, val_y), total=val_term_doc.shape[0]):\n",
    "    val_scores.append(score(net_a(x),y))\n",
    "print(np.mean(to_np(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_acc_scores = []\n",
    "    for x, y in tqdm(zip(trn_term_doc, trn_y), total=trn_term_doc.shape[0]):\n",
    "        train_acc_scores.append(score(net_a(x),y))\n",
    "    l3 = np.mean(to_np(train_acc_scores))\n",
    "    print(l3)\n",
    "\n",
    "    acc_scores = []\n",
    "    for x, y in tqdm(zip(val_term_doc, val_y), total=val_term_doc.shape[0]):\n",
    "        acc_scores.append(score(net_a(x),y))\n",
    "    l4 = np.mean(to_np(acc_scores))\n",
    "    print(l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.001\n",
      "100%|██████████| 25000/25000 [00:07<00:00, 3197.62it/s]\n",
      "100%|██████████| 25000/25000 [00:07<00:00, 3258.21it/s]\n",
      "100%|██████████| 25000/25000 [00:04<00:00, 5054.64it/s]\n",
      "100%|██████████| 25000/25000 [00:04<00:00, 5047.96it/s]\n",
      "epoch=0, train-loss=0.4026816487312317\n",
      "epoch=0, valid-loss=0.8581857085227966\n",
      "epoch=0, train-acc=0.90968\n",
      "epoch=0, valid-acc=0.82844\n",
      "\n",
      "epoch: 0\n",
      "time: 2020-01-06 00:33:04.901118\n",
      "100%|██████████| 25000/25000 [00:23<00:00, 1084.23it/s]\n",
      "100%|██████████| 25000/25000 [00:07<00:00, 3537.56it/s]\n",
      "100%|██████████| 25000/25000 [00:07<00:00, 3559.92it/s]\n",
      "100%|██████████| 25000/25000 [00:04<00:00, 5045.30it/s]\n",
      "100%|██████████| 25000/25000 [00:04<00:00, 5040.32it/s]\n",
      "epoch=1, train-loss=0.3187373876571655\n",
      "epoch=1, valid-loss=0.7220572829246521\n",
      "epoch=1, train-acc=0.9244\n",
      "epoch=1, valid-acc=0.84884\n",
      "\n",
      "epoch: 1\n",
      "time: 2020-01-06 00:33:52.875047\n",
      "100%|██████████| 25000/25000 [00:22<00:00, 1088.76it/s]\n",
      "100%|██████████| 25000/25000 [00:07<00:00, 3548.97it/s]\n",
      "100%|██████████| 25000/25000 [00:07<00:00, 3570.43it/s]\n",
      "100%|██████████| 25000/25000 [00:04<00:00, 5058.15it/s]\n",
      "100%|██████████| 25000/25000 [00:04<00:00, 5045.47it/s]\n",
      "epoch=2, train-loss=0.2826773226261139\n",
      "epoch=2, valid-loss=0.6739591360092163\n",
      "epoch=2, train-acc=0.93152\n",
      "epoch=2, valid-acc=0.856\n",
      "\n",
      "epoch: 2\n",
      "time: 2020-01-06 00:34:40.678086\n",
      " 64%|██████▎   | 15899/25000 [00:14<00:08, 1050.98it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-a7137d2b1fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# compute gradient of the loss with respect to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mnet_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnet_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# net2.b.data -= net2.b.grad.data * lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f'lr={lr}')\n",
    "f = open(filename, 'a')\n",
    "\n",
    "from datetime import datetime\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "train_acc_list = []\n",
    "\n",
    "# loss_list = [0]\n",
    "loss_list = []\n",
    "for epoch in range(5000):\n",
    "    if epoch % 1 == 0:\n",
    "        train_scores = []\n",
    "        for x, y in tqdm(zip(trn_term_doc, trn_y), total=trn_term_doc.shape[0]):\n",
    "            train_scores.append(loss(net_a(x), V(y)))\n",
    "        l1 = np.mean(to_np(train_scores))\n",
    "        train_loss_list.append(l1)\n",
    "\n",
    "        val_scores = []\n",
    "        for x, y in tqdm(zip(val_term_doc, val_y), total=val_term_doc.shape[0]):\n",
    "            val_scores.append(loss(net_a(x), V(y)))\n",
    "        l2 = np.mean(to_np(val_scores))\n",
    "        val_loss_list.append(l2)\n",
    "\n",
    "        train_acc_scores = []\n",
    "        for x, y in tqdm(zip(trn_term_doc, trn_y), total=trn_term_doc.shape[0]):\n",
    "            train_acc_scores.append(score(net_a(x),y))\n",
    "        l3 = np.mean(to_np(train_acc_scores))\n",
    "        train_acc_list.append(l3)\n",
    "        \n",
    "        acc_scores = []\n",
    "        for x, y in tqdm(zip(val_term_doc, val_y), total=val_term_doc.shape[0]):\n",
    "            acc_scores.append(score(net_a(x),y))\n",
    "        l4 = np.mean(to_np(acc_scores))\n",
    "        val_acc_list.append(l4)\n",
    "\n",
    "        # print(f'epoch={epoch}, score={np.mean(val_scores)}')\n",
    "        # print(f'epoch={epoch}, score={l2}')\n",
    "        print(f'epoch={epoch}, train-loss={l1}')\n",
    "        print(f'epoch={epoch}, valid-loss={l2}')\n",
    "        print(f'epoch={epoch}, train-acc={l3}')\n",
    "        print(f'epoch={epoch}, valid-acc={l4}')\n",
    "        f.write(f\"{epoch}\\t{l1}\\t{l2}\\t{l3}\\t{l4}\\t{nb_score}\\t{lr_score}\\t{lr_score2}\\n\")\n",
    "        f.flush()\n",
    "\n",
    "    print('')\n",
    "    print('epoch:', epoch)\n",
    "    print('time:', datetime.now())\n",
    "    shuffle_x, shuffle_y = shuffle(trn_term_doc, trn_y)\n",
    "    for _x, _y in tqdm(zip(shuffle_x, shuffle_y), total=shuffle_x.shape[0]):\n",
    "        _y_pred = net_a(_x)\n",
    "        l = loss(_y_pred, V(_y))\n",
    "        # l = loss(yt, y_pred)\n",
    "        loss_list.append(l)\n",
    "        # print(f'{index}, {l}, {datetime.now().time()}')\n",
    "\n",
    "        # Backward pass: \n",
    "        # compute gradient of the loss with respect to \n",
    "        # model parameters\n",
    "        l.backward()\n",
    "        net_a.w.weight.data -= net_a.w.weight.grad.data * lr\n",
    "        # net2.b.data -= net2.b.grad.data * lr\n",
    "        \n",
    "        net_a.w.weight.grad.data.zero_()\n",
    "        # net2.b.grad.data.zero_()   \n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "len(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=len(train_loss_list)\n",
    "df = pd.DataFrame({\n",
    "    'train':train_loss_list[:length], \n",
    "    'valid':val_loss_list[:length],\n",
    "    'train_acc':train_acc_list[:length], \n",
    "    'valid_acc':val_acc_list[:length]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['train','valid']].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list[:1280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:light",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
